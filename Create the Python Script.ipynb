# Step1: Create the Python Script

In the cell below, you will need to complete the Python script and run the cell to generate the file using the magic `%%writefile` command. Your main task is to complete the following methods for the `PersonDetect` class:
* `load_model`
* `predict`
* `draw_outputs`
* `preprocess_outputs`
* `preprocess_inputs`

For your reference, here are all the arguments used for the argument parser in the command line:
* `--model`:  The file path of the pre-trained IR model, which has been pre-processed using the model optimizer. There is automated support built in this argument to support both FP32 and FP16 models targeting different hardware.
* `--device`: The type of hardware you want to load the model on (CPU, GPU, MYRIAD, HETERO:FPGA,CPU)
* `--video`: The file path of the input video.
* `--output_path`: The location where the output stats and video file with inference needs to be stored (results/[device]).
* `--max_people`: The max number of people in queue before directing a person to another queue.
* `--threshold`: The probability threshold value for the person detection. Optional arg; default value is 0.60.

%%writefile person_detect.py

import numpy as np
import time
from openvino.inference_engine import IENetwork, IECore
import os
import cv2
import argparse
import sys


class Queue:
    '''
    Class for dealing with queues
    '''
    def __init__(self):
        self.queues=[]

    def add_queue(self, points):
        self.queues.append(points)

    def get_queues(self, image):
        for q in self.queues:
            x_min, y_min, x_max, y_max=q
            frame=image[y_min:y_max, x_min:x_max]
            yield frame
    
    def check_coords(self, coords):
        d={k+1:0 for k in range(len(self.queues))}
        for coord in coords:
            for i, q in enumerate(self.queues):
                if coord[0]>q[0] and coord[2]<q[2]:
                    d[i+1]+=1
        return d


class PersonDetect:
    '''
    Class for the Person Detection Model.
    '''

    def __init__(self, model_name, device, threshold=0.60):
        self.model_weights=model_name+'.bin'
        self.model_structure=model_name+'.xml'
        self.device=device
        self.threshold=threshold

        try:
            self.model=IENetwork(self.model_structure, self.model_weights)
        except Exception as e:
            raise ValueError("Could not Initialise the network. Have you enterred the correct model path?")

        self.input_name=next(iter(self.model.inputs))
        self.input_shape=self.model.inputs[self.input_name].shape
        self.output_name=next(iter(self.model.outputs))
        self.output_shape=self.model.outputs[self.output_name].shape

    # To load the model
    def load_model(self):
    '''
    TODO: Load model using Inference Engine
    '''
       try:
            self.core = IECore()
            self.exec_network = self.core.load_network(network= self.model, device_name= self.device, num_requests= 1)
        except Exception as e:
            raise NotImplementedError("The model could not be loaded to IE...")
          
    # predict the existing models
    def predict(self, image):
    '''
    TODO: to predict the output of your model, it should use draw_outputs 
    '''
       try:
            infer_image = preprocess_input(image)
            input_predict = {self.input_name: infer_image}
            result = self.exec_network.infer(input_predict)
            post_result = preprocess_outputs(result)
            coordinates, post_frame = draw_outputs(post_result, image)
        except Exception as e:
            raise NotImplementedError
        return coordinates, post_frame
    
    # to draw outputs
    def draw_outputs(self, coords, image):
    '''
    TODO:  to draw the bounding box 
    '''
        width = int(image.shape[1]) 
        height = int(image.shape[0])
        
        # Bounding box color
        box_color = (0, 0, 255) # "BLUE": (255,0,0), "GREEN": (0,255,0), "RED": (0,0,255)


        # Box thickness
        box_thickness = 3
        
        for coord in coords:

            conf = obj[2]
            
            if(conf >= self.threshold): #label == 1 and
                x_min = int(coord[3] * width)
                y_min = int(coord[4] * height)
                x_max = int(coord[5] * width)
                y_max = int(coord[6] * height)
                coords = (x_min, y_min, x_max, y_max)
                cv2.rectangle(image, (x_min, y_min), (x_max, y_max),  box_color, box_thickness)
        return coords, image

    # To see output for precocess model
    def preprocess_outputs(self, outputs):
    '''
    TODO: to pre-process the output from model. It could have rules to check whether person 
    is in the frame or not by checking the threshold.
    '''
         try:
            output = np.squeeze(outputs)
        except:
            raise NotImplementedError
        return output
        
    # To see to see for precocess model
    def preprocess_input(self, image):
    '''
    TODO:  Apply the pre-processing steps to the input frame like resizing etc.
    '''
        try:
            n, c, h, w = self.input_shape
            input_img=cv2.resize(image, (w, h))
            input_img = input_img.transpose(2,0,1)
            input_img = input_image.reshape((n, c, h, w))
        except:
            raise NotImplementedError
        return input_img


def main(args):
    model=args.model
    device=args.device
    video_file=args.video
    max_people=args.max_people
    threshold=args.threshold
    output_path=args.output_path

    start_model_load_time=time.time()
    pd= PersonDetect(model, device, threshold)
    pd.load_model()
    total_model_load_time = time.time() - start_model_load_time

    queue=Queue()
    
    try:
        queue_param=np.load(args.queue_param)
        for q in queue_param:
            queue.add_queue(q)
    except:
        print("error loading queue param file")

    try:
        cap=cv2.VideoCapture(video_file)
    except FileNotFoundError:
        print("Cannot locate video file: "+ video_file)
    except Exception as e:
        print("Something else went wrong with the video file: ", e)
    
    initial_w = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    initial_h = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    video_len = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    # Write to the output video
    out_video = cv2.VideoWriter(os.path.join(output_path, 'output_video.mp4'), cv2.VideoWriter_fourcc(*'avc1'), fps, (initial_w, initial_h), True)
    
    counter=0
    start_inference_time=time.time()

    try:
        while cap.isOpened():
            # this return capture video
            ret, frame=cap.read()
            # if not return capture video
            if not ret:
                break
            counter+=1
            
            coords, image= pd.predict(frame)
            num_people= queue.check_coords(coords)
            print(f"Total number of People in frame = {len(coords)}")
            print(f"Number of people in queue = {num_people}")
            out_text=""
            y_pixel=25
            
            for k, v in num_people.items():
                out_text += f"No. of People in Queue: {k} is {v} "
                if v >= int(max_people):
                    out_text += f" Queue is full; Please move to next Queue."
                cv2.putText(image, out_text, (18, y_pixel), cv2.FONT_HERSHEY_COMPLEX, 1, (0, 0, 255), 2)
                out_text=""
                y_pixel+=40
            out_video.write(image)
        
        #total inference time
        total_time=time.time()-start_inference_time
        total_inference_time=round(total_time, 1)
        fps=counter/total_inference_time
        # Use file to refer to the file object
        with open(os.path.join(output_path, 'stats.txt'), 'w') as f:
            f.write(str(total_inference_time)+'\n')
            f.write(str(fps)+'\n')
            f.write(str(total_model_load_time)+'\n')

        cap.release()
        cv2.destroyAllWindows()
    except Exception as e:
        print("Could not run Inference: ", e)

if __name__=='__main__':
    parser=argparse.ArgumentParser()
    parser.add_argument('--model', required=True)
    parser.add_argument('--device', default='CPU')
    parser.add_argument('--video', default=None)
    parser.add_argument('--queue_param', default=None)
    parser.add_argument('--output_path', default='/results')
    parser.add_argument('--max_people', default=2)
    parser.add_argument('--threshold', default=0.60)
    
    args=parser.parse_args()

    main(args)

# Next Step

Now that you've run the above cell and created your Python script, you will create your job submission shell script in the next workspace.

**Note**: As a reminder, if you need to make any changes to the Python script, you can come back to this workspace to edit and run the above cell to overwrite the file with your changes.